---
title: "BOSTON - Regression - H2o and Dalex"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    number_sections: yes
    fig_height: 10
    fig_width: 14
    highlight: kate
    toc_depth: 3
    css: style.css
    
---

Based on Jo-fai Chow's bit.ly/useR2019_h2o_tutorial

---
DA October 2019

Remove DT code due to display issues

Replace deprecated packages and use new functions...

Add extra packages and functions...

## R Packages - Setup

```{r}
pkgs <- c("h2o", "DALEX", "iBreakDown", "pdp", "vip", "ingredients", "iml",
          "knitr", "rmdformats", "DT", "xgboost", "mlbench")
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}

```


```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)
library(DT) # create an HTML widget to display R data objects with JS DataTables

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

# Regression Part One: H2O AutoML

```{r, message=FALSE}
# Let's go
library(h2o) # for H2O Machine Learning
library(mlbench) # for Datasets
```

```{r}
# seed for reproducibility...
n_seed <- 12345
```

## Data - Boston Housing from `mlbench`

```{r}
data("BostonHousing")
head(BostonHousing) 
          
```

**Source**: UCI Machine Learning Repository [Link](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/)

- **crim**: per capita crime rate by town.
- **zn**: proportion of residential land zoned for lots over 25,000 sq.ft.
- **indus**: proportion of non-retail business acres per town.
- **chas**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
- **nox**: nitrogen oxides concentration (parts per 10 million).
- **rm**: average number of rooms per dwelling.
- **age**: proportion of owner-occupied units built prior to 1940.
- **dis**: weighted mean of distances to five Boston employment centres.
- **rad**: index of accessibility to radial highways.
- **tax**: full-value property-tax rate per $10,000.
- **ptratio**: pupil-teacher ratio by town.
- **b**: 1000(Bk - 0.63)^2 where Bk is the proportion of people of African American descent by town.
- **lstat**: lower status of the population (percent).
- **medv** (This is the **TARGET**): median value of owner-occupied homes in $1000s.


## **b** and **lstat** are highly discriminatory variables - in production need to be excluded and proxies checked for...


## Define Target and Features

```{r}
target <- "medv" # Median House Value
features <- setdiff(colnames(BostonHousing), target)
print(features)
```

## Start a local H2O Cluster (JVM)

```{r}
h2o.init()
```

```{r}
h2o.no_progress() # disable progress bar for RMarkdown
h2o.removeAll()   # Optional: remove anything from previous session 
```


## Convert R dataframe into H2O dataframe

```{r}
# H2O dataframe
h_boston <- as.h2o(BostonHousing)
```


## Split Data into Train/Test

```{r}
h_split <- h2o.splitFrame(h_boston, ratios = 0.8, seed = n_seed)
h_train <- h_split[[1]] # 80% for modelling
h_test <- h_split[[2]] # 20% for evaluation
```

## Dimensions 

```{r}
dim(h_train)
dim(h_test)
```

## Cross-Validation

## Baseline Models

- `h2o.glm()`: H2O Generalized Linear Model
- `h2o.randomForest()`: H2O Random Forest Model
- `h2o.gbm()`: H2O Gradient Boosting Model
- `h2o.deeplearning()`: H2O Deep Neural Network Model 
- `h2o.xgboost()`: H2O wrapper for eXtreme Gradient Boosting Model from DMLC

### Baseline Generalized Linear Model (GLM)

```{r}
model_glm <- h2o.glm(x = features,               # All 13 features
                     y = target,                 # medv (median value of owner-occupied homes in $1000s)
                     training_frame = h_train,   # H2O dataframe with training data
                     model_id = "baseline_glm",  # Give the model a name
                     nfolds = 5,                 # Using 5-fold CV
                     seed = n_seed)              # control the randomization
```

```{r}
# Cross-Validation
model_glm@model$cross_validation_metrics
```

## Evaluate model on the hold out data
```{r}
# Evaluate performance on test
h2o.performance(model_glm, newdata = h_test)
```

Using RMSE

### Build Other Baseline Models (DRF, GBM, DNN & XGB)

```{r}
# Baseline Distributed Random Forest (DRF)
model_drf <- h2o.randomForest(x = features,
                              y = target,
                              training_frame = h_train,
                              model_id = "baseline_drf",
                              nfolds = 5,
                              seed = n_seed)
```

```{r}
# Baseline Gradient Boosting Model (GBM)
model_gbm <- h2o.gbm(x = features,
                     y = target,
                     training_frame = h_train,
                     model_id = "baseline_gbm",
                     nfolds = 5,
                     seed = n_seed)
```

```{r}
# Baseline Deep Nerual Network (DNN)
# By default, DNN is not reproducible with multi-core. You may get slightly different results here.
# You can enable the `reproducible` option but it will run on a single core (very slow).
model_dnn <- h2o.deeplearning(x = features, 
                              y = target, 
                              training_frame = h_train,
                              model_id = "baseline_dnn", 
                              nfolds = 5, 
                              seed = n_seed)
```

### Comparison (RMSE: Lower = Better)

```{r}
# Create a table to compare RMSE from different models
d_eval <- data.frame(model = c("H2O GLM: Generalized Linear Model (Baseline)", 
                               "H2O DRF: Distributed Random Forest (Baseline)",
                               "H2O GBM: Gradient Boosting Model (Baseline)",
                               "H2O DNN: Deep Neural Network (Baseline)"),
                     stringsAsFactors = FALSE)
d_eval$RMSE_cv <- NA
d_eval$RMSE_test <- NA
```

```{r}
# Store RMSE values
d_eval[1, ]$RMSE_cv <- model_glm@model$cross_validation_metrics@metrics$RMSE
d_eval[2, ]$RMSE_cv <- model_drf@model$cross_validation_metrics@metrics$RMSE
d_eval[3, ]$RMSE_cv <- model_gbm@model$cross_validation_metrics@metrics$RMSE
d_eval[4, ]$RMSE_cv <- model_dnn@model$cross_validation_metrics@metrics$RMSE

d_eval[1, ]$RMSE_test <- h2o.rmse(h2o.performance(model_glm, newdata = h_test))
d_eval[2, ]$RMSE_test <- h2o.rmse(h2o.performance(model_drf, newdata = h_test))
d_eval[3, ]$RMSE_test <- h2o.rmse(h2o.performance(model_gbm, newdata = h_test))
d_eval[4, ]$RMSE_test <- h2o.rmse(h2o.performance(model_dnn, newdata = h_test))

```

```{r}
# Show Comparison (RMSE: Lower = Better)
d_eval
```

## Manual Tuning

### Check out the hyper-parameters for each algo

```{r, eval=FALSE}
?h2o.glm 
?h2o.randomForest
?h2o.gbm
?h2o.deeplearning
```


## H2O AutoML
```{r}
?h2o.automl
```

```{r}
# Run AutoML (try n different models)
# Check out all options using ?h2o.automl
automl = h2o.automl(x = features,
                    y = target,
                    training_frame = h_train,
                    max_runtime_secs = 120, 
                    nfolds = 5,                     # 5-fold Cross-Validation
                    max_models = 10,                # Max number of models
                    stopping_metric = "RMSE",       # Metric to optimize
                    project_name = "automl_boston", # Specify a name so you can add more models later
                    seed = n_seed)
```

### Leaderboard

```{r}
as.data.frame(automl@leaderboard)
```

### Best Model (Leader)

```{r}
automl@leader
```

### Comparison (RMSE: Lower = Better)

```{r}
d_eval_tmp <- data.frame(model = "Best Model from H2O AutoML",
                         RMSE_cv = automl@leader@model$cross_validation_metrics@metrics$RMSE,
                         RMSE_test = h2o.rmse(h2o.performance(automl@leader, newdata = h_test)))
d_eval <- rbind(d_eval, d_eval_tmp)

d_eval
```



## Make Predictions

```{r}
yhat_test <- h2o.predict(automl@leader, newdata = h_test)
head(yhat_test)
```



# Regression Part Two: Interpretable ML

Let's look at the first house in `h_test`

```{r}
as.data.frame(h_test[1, ])
```


## Using functions in `h2o`

- `h2o.varimp()` & `h2o.varimp_plot`: Variable Importance (for GBM, DNN, GLM)
- `h2o.partialPlot()`: Partial Dependence Plots
- `h2o.predict_contributions()`: SHAP values (for GBM and XGBoost only)

```{r, eval=FALSE}
# Look at the impact of feature `rm` (no. of rooms)
# Not Run
h2o.partialPlot(model_glm, data = h_test, cols = c("rm"))
h2o.partialPlot(model_drf, data = h_test, cols = c("rm"))
h2o.partialPlot(model_gbm, data = h_test, cols = c("rm"))
h2o.partialPlot(model_dnn, data = h_test, cols = c("rm"))
h2o.partialPlot(automl@leader, data = h_test, cols = c("rm"))
```


## Package `DALEX`

```{r}
# Descriptive mAchine Learning EXplanations (DALEX)
library(DALEX)
```

- Website: https://pbiecek.github.io/DALEX/
- Original DALEX-H2O Example: https://raw.githack.com/pbiecek/DALEX_docs/master/vignettes/DALEX_h2o.html

### The `explain()` Function

The first step of using the `DALEX` package is to wrap-up the black-box model with meta-data that unifies model interfacing.

To create an explainer we use `explain()` function. Validation dataset for the models is `h_test` from part one. For the models created by `h2o` package we have to provide custom predict function which takes two arguments:  `model` and `newdata` and returns a numeric vector with predictions.

```{r}
# Custom Predict Function
custom_predict <- function(model, newdata) {
  newdata_h2o <- as.h2o(newdata)
  res <- as.data.frame(h2o.predict(model, newdata_h2o))
  return(as.numeric(res$predict))
  }
```

### Explainer for H2O Models

```{r}
explainer_glm <- DALEX::explain(model = model_glm, 
                                data = as.data.frame(h_test)[, features],
                                y = as.data.frame(h_test)[, target],
                                predict_function = custom_predict,
                                label = "GLM")

explainer_drf <- DALEX::explain(model = model_drf, 
                                data = as.data.frame(h_test)[, features],
                                y = as.data.frame(h_test)[, target],
                                predict_function = custom_predict,
                                label = "Random Forest")

explainer_dnn <- DALEX::explain(model = model_dnn, 
                                data = as.data.frame(h_test)[, features],
                                y = as.data.frame(h_test)[, target],
                                predict_function = custom_predict,
                                label = "Deep Neural Networks")

explainer_gbm <- DALEX::explain(model = model_gbm, 
                                data = as.data.frame(h_test)[, features],
                                y = as.data.frame(h_test)[, target],
                                predict_function = custom_predict,
                                label = "GBM")

explainer_automl <- DALEX::explain(model = automl@leader, 
                                data = as.data.frame(h_test)[, features],
                                y = as.data.frame(h_test)[, target],
                                predict_function = custom_predict,
                                label = "H2O AutoML")
```

### Variable importance

Using the DALEX and ingredients packages we are able to better understand which variables are important.

Model agnostic variable importance is calculated by means of permutations. We simply substract the loss function calculated for validation dataset with permuted values for a single variable from the loss function calculated for validation dataset.

This method is implemented in the feature_importance() function.

```{r}
library(ingredients)

vi_glm <- ingredients::feature_importance(explainer_glm, type="difference")
vi_drf <- ingredients::feature_importance(explainer_drf, type="difference")
vi_dnn <- ingredients::feature_importance(explainer_dnn, type="difference")
vi_gbm <- ingredients::feature_importance(explainer_gbm, type="difference")
vi_automl <- ingredients::feature_importance(explainer_automl, type="difference")
```

```{r}
plot(vi_glm, vi_drf, vi_dnn, vi_gbm, vi_automl)
# click show in New Window for better visibility
```

### Partial Dependence Plots

Partial Dependence Plots (PDP) are one of the most popular methods for exploration of the relation between a continuous variable and the model outcome. Function partial_dependency() with the parameter type = "pdp" calls pdp::partial() function to calculate PDP response.

Hold everything else constant and vary one variable then aggregate the profile.

Feature `rm` (no. of rooms)

```{r}
pdp_glm_rm <- ingredients::partial_dependency(explainer_glm, variables = "rm")
pdp_drf_rm <- ingredients::partial_dependency(explainer_drf, variables = "rm")
pdp_dnn_rm <- ingredients::partial_dependency(explainer_dnn, variables = "rm")
pdp_gbm_rm <- ingredients::partial_dependency(explainer_gbm, variables = "rm")
pdp_automl_rm <- ingredients::partial_dependency(explainer_automl, variables = "rm")
```

```{r}
# Not always working on my PC...
plot(pdp_glm_rm, pdp_drf_rm, pdp_dnn_rm, pdp_gbm_rm, pdp_automl_rm)
```
## ALE Plots and Ceteris plots

```{r}
# Accumulated - handle correlation better
# conditional_dependency functions...
```

```{r}
ale_glm_rm <- ingredients::accumulated_dependency(explainer_glm, variables = "rm")
ale_drf_rm <- ingredients::accumulated_dependency(explainer_drf, variables = "rm")
ale_dnn_rm <- ingredients::accumulated_dependency(explainer_dnn, variables = "rm")
ale_gbm_rm <- ingredients::accumulated_dependency(explainer_gbm, variables = "rm")
ale_automl_rm <- ingredients::accumulated_dependency(explainer_automl, variables = "rm")
```

```{r}
# Not always working on my PC...
plot(ale_glm_rm,ale_drf_rm, ale_dnn_rm, ale_gbm_rm, ale_automl_rm)
```
```{r}
# Conditional_dependency (aka Local Profiles)
```

```{r}
cdp_glm_rm <- ingredients::conditional_dependency(explainer_glm, variables = "rm")
cdp_drf_rm <- ingredients::conditional_dependency(explainer_drf, variables = "rm")
cdp_dnn_rm <- ingredients::conditional_dependency(explainer_dnn, variables = "rm")
cdp_gbm_rm <- ingredients::conditional_dependency(explainer_gbm, variables = "rm")
cdp_automl_rm <- ingredients::conditional_dependency(explainer_automl, variables = "rm")
```

```{r}
# Not always working on my PC...
plot(cdp_glm_rm, cdp_drf_rm, cdp_dnn_rm, cdp_gbm_rm, cdp_automl_rm)
```

### (Local) Prediction Understanding

```{r}
# Predictions from different models
yhat <- data.frame(model = c("H2O GLM: General Linear Model (Baseline)",
                             "H2O DRF: Distributed Random Forest (Baseline)",
                             "H2O DNN: Deep Neural Network (Baseline)",
                             "H2O GBM: Gradient Boosting Model (Baseline)",
                             "Best Model from H2O AutoML"))
yhat$prediction <- NA
yhat[1,]$prediction <- as.matrix(h2o.predict(model_glm, h_test[1,]))
yhat[2,]$prediction <- as.matrix(h2o.predict(model_drf, h_test[1,]))
yhat[3,]$prediction <- as.matrix(h2o.predict(model_dnn, h_test[1,]))
yhat[4,]$prediction <- as.matrix(h2o.predict(model_gbm, h_test[1,]))
yhat[5,]$prediction <- as.matrix(h2o.predict(automl@leader, h_test[1,]))

# Show the predictions
datatable(yhat, rownames = FALSE, options = list(pageLength = 10, scrollX = TRUE)) %>%
  formatRound(columns = -1, digits = 3)
```

The function `break_down()` is a wrapper around the `IBreakDown` package. Model prediction is visualized with Break Down Plots, which show the contribution of every variable present in the model. This function generates variable attributions for selected prediction. The generic `plot()` function shows these attributions.

```{r}
library(iBreakDown)

sample <- as.data.frame(h_test)[1, ]     # Using the first sample from h_test
pb_glm <- break_down(explainer_glm, new_observation = sample)
pb_drf <- break_down(explainer_drf, new_observation = sample)
pb_dnn <- break_down(explainer_dnn, new_observation = sample)
pb_gbm <- break_down(explainer_gbm, new_observation = sample)
pb_automl <- break_down(explainer_automl, new_observation = sample)
```

```{r}
plot(pb_glm)
plot(pb_drf)
plot(pb_dnn)
plot(pb_gbm)
plot(pb_automl)
```

```{r}
# terminate the JVM engine - get the memory back...
h2o.shutdown()
```



